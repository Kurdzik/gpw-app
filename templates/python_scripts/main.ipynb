{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"postgresql://j341:ED1F_a359b0@psql01.mikr.us:5432/db_j341\")\n",
    "conn = engine.connect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpw_functions import get_stock_prices\n",
    "from datetime import date\n",
    "import sqlite3\n",
    "\n",
    "def day():\n",
    "    if date.today().day<10:\n",
    "        return '0' + str(date.today().day)\n",
    "    else:\n",
    "        return str(date.today().day)\n",
    "\n",
    "def month():\n",
    "    if date.today().month<10:\n",
    "        return '0' + str(date.today().month)\n",
    "    else:\n",
    "        return str(date.today().month)\n",
    "    \n",
    "def year():\n",
    "    if date.today().year<10:\n",
    "        return '0' + str(date.today().year)\n",
    "    else:\n",
    "        return str(date.today().year)\n",
    "\n",
    "# Get date in a correct format\n",
    "stocs_date = f'{day()}-{month()}-{year()}'\n",
    "\n",
    "# Get stock prices for that date\n",
    "data = get_stock_prices(stocs_date,stocs_date)\n",
    "\n",
    "# Get all registered connection stirings\n",
    "conn_creds = sqlite3.connect('../static/db_credentials/creds_DB.db')\n",
    "creds = pd.read_sql('select * from connected_dbs.connections', con=conn)\n",
    "\n",
    "# Iterate through conn strings and upload the data\n",
    "for conn_string in creds.iterrows():\n",
    "    try:\n",
    "        data.to_sql(conn_string[1][1],con = conn_string[1][0], schema = conn_string[1][2],if_exists = 'append')\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "engine = sqlalchemy.create_engine(\"postgresql://j341:ED1F_a359b0@psql01.mikr.us:5432/db_j341\")\n",
    "conn = engine.connect()\n",
    "\n",
    "q = f\"\"\"select distinct * from gpw.notowania\"\"\"\n",
    "df = pd.read_sql(q,con=conn)\n",
    "\n",
    "dates_list = []\n",
    "for date in pd.to_datetime(df['Date'],format=\"%d-%m-%Y\").sort_values().unique().astype(str):\n",
    "    dates_list.append(date[:10])\n",
    "   \n",
    "# Updae dates dropdowns\n",
    "with open('../static/dropdown/dates_to.csv','w') as file:\n",
    "    for line in dates_list:\n",
    "        file.write(line + ',')\n",
    "        file.write('\\n')\n",
    "\n",
    "shutil.copy('../static/dropdown/dates_to.csv','../static/dropdown/dates_from.csv')\n",
    "\n",
    "# Update prediction tickers dropdown\n",
    "with open('../static/dropdown/tickers_preds.csv','w') as file:\n",
    "    for line in ['ALL'] + df['Ticker'].unique().tolist():\n",
    "        file.write(line + ',')\n",
    "        file.write('\\n')\n",
    "\n",
    "# Update tickers dropdown\n",
    "with open('../static/dropdown/tickers.csv','w') as file:\n",
    "    for line in ['ALL'] + df['Ticker'].unique().tolist():\n",
    "        file.write(line + ',')\n",
    "        file.write('\\n')\n",
    "\n",
    "# Clear downloads\n",
    "path = '../static/downloads/'\n",
    "for file in os.listdir(path):\n",
    "    os.remove(path + file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, collected total of 421 records                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "\n",
    "from gpw_functions import get_stock_prices\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"postgresql://j341:ED1F_a359b0@psql01.mikr.us:5432/db_j341\")\n",
    "conn = engine.connect()\n",
    "\n",
    "from gpw_functions import get_stock_prices\n",
    "from datetime import date\n",
    "import sqlite3\n",
    "\n",
    "def day():\n",
    "    if date.today().day<10:\n",
    "        return '0' + str(date.today().day)\n",
    "    else:\n",
    "        return str(date.today().day)\n",
    "\n",
    "def month():\n",
    "    if date.today().month<10:\n",
    "        return '0' + str(date.today().month)\n",
    "    else:\n",
    "        return str(date.today().month)\n",
    "    \n",
    "def year():\n",
    "    if date.today().year<10:\n",
    "        return '0' + str(date.today().year)\n",
    "    else:\n",
    "        return str(date.today().year)\n",
    "\n",
    "# Get date in a correct format\n",
    "stocs_date = f'{day()}-{month()}-{year()}'\n",
    "\n",
    "# Get stock prices for that date\n",
    "data = get_stock_prices(stocs_date,stocs_date)\n",
    "\n",
    "# Get all registered connection stirings\n",
    "conn_creds = sqlite3.connect('../static/db_credentials/creds_DB.db')\n",
    "creds = pd.read_sql('select * from connected_dbs.connections', con=conn)\n",
    "\n",
    "# Iterate through conn strings and upload the data\n",
    "for conn_string in creds.iterrows():\n",
    "    try:\n",
    "        data.to_sql(conn_string[1][1],con = conn_string[1][0], schema = conn_string[1][2],if_exists = 'append')\n",
    "    except Exception:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpw_functions import get_stock_prices\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"postgresql://j341:ED1F_a359b0@psql01.mikr.us:5432/db_j341\")\n",
    "conn = engine.connect()\n",
    "\n",
    "starts = ['01-01-2010','01-01-2011','01-01-2012','01-01-2013','01-01-2014','01-01-2015','01-01-2016','01-01-2017','01-01-2018','01-01-2019','01-01-2020','01-01-2021','01-01-2022']\n",
    "stops = ['31-12-2010','31-12-2011','31-12-2012','31-12-2013','31-12-2014','31-12-2015','31-12-2016','31-12-2017','31-12-2018','31-12-2019','31-12-2020','31-12-2021','09-09-2022']\n",
    "\n",
    "for start,stop in zip(starts,stops):\n",
    "\n",
    "    df = get_stock_prices(start,stop)\n",
    "    df.to_sql('notowania',schema='gpw',con=conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MM DD RRRR\n",
    "date_from = '02-01-2015'\n",
    "day_from = date_from[:2]\n",
    "month_from = date_from[3:5]\n",
    "year_from = date_from[-4:]\n",
    "\n",
    "date_to = '05-01-2015'\n",
    "day_to = date_to[:2]\n",
    "month_to = date_to[3:5]\n",
    "year_to = date_to[-4:]\n",
    "\n",
    "\n",
    "q = f\"\"\"select * from gpw.notowania where Date_new > '{year_from}-{month_from}-{day_from}' and Date_new <= '{year_to}-{month_to}-{day_to}' \"\"\"\n",
    "\n",
    "df = pd.read_sql(q,con=conn).drop(columns=['level_0','index'])\n",
    "df.loc[df['Ticker'].str.contains('06')]\n",
    "\n",
    "## POTRZEBA RRRR MM DD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Date'] = df.Date.apply(lambda x: str(x))\n",
    "df['Date_new'] = df.Date.str[-4:]+'-'+df.Date.str[3:5]+'-'+df.Date.str[:2]\n",
    "df.to_sql('notowania',con=conn, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_db(date_from,date_to,ticker):\n",
    "    \n",
    "    engine = create_engine(\"mysql+pymysql://test_user:Kolesgit99!@192.168.88.199:3307/GPW?charset=utf8mb4\")\n",
    "    conn = engine.connect()\n",
    "\n",
    "    q = f\"\"\"select * from notowania where Date_new > '{year_from}-{month_from}-{day_from}' and Date_new <= '{year_to}-{month_to}-{day_to}' \"\"\"\n",
    "\n",
    "    df = pd.read_sql(q,con=conn).drop(columns=['level_0','index'])\n",
    "\n",
    "\n",
    "    if ticker=='ALL':\n",
    "        return df\n",
    "        \n",
    "    else:\n",
    "        return df.loc[df['Ticker'].str.contains(ticker)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_conn(db_type,db_user,db_pass,db_ip,db_port,database):\n",
    "\n",
    "    if db_type=='PostgreSQL':\n",
    "        engine = create_engine(f\"\"\"postgresql://{db_user}:{db_pass}@{db_ip}:{db_port}/{database}\"\"\")      \n",
    "\n",
    "    elif db_type=='MySQL':\n",
    "        engine = create_engine(f\"\"\"mysql://{db_user}:{db_pass}@{db_ip}:{db_port}/{database}\"\"\")\n",
    "\n",
    "    elif db_type=='Oracle':\n",
    "        engine = create_engine(f\"\"\"oracle://{db_user}:{db_pass}@{db_ip}:{db_port}/{database}\"\"\")\n",
    "\n",
    "    elif db_type=='SQL Server':\n",
    "        engine = create_engine(f\"\"\"mssql+pymssql://{db_user}:{db_pass}@{db_ip}:{db_port}/{database}\"\"\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        engine.connect()\n",
    "        msg = 'Connected!'        \n",
    "        return engine, msg\n",
    "\n",
    "    except Exception:\n",
    "        msg = 'Check your db credentials'\n",
    "        return engine, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('../static/db_credentials/creds.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "conn_str = ['postgresql://test_user:Kolesgit99!@192.168.88.199:3306/otomoto','active']\n",
    "pd.DataFrame(conn_str).T.rename({0:'connection_string',1:'status'},axis=1).to_sql('connections',if_exists='append',con=conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'select * from connections'\n",
    "pd.read_sql(q,con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('app_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14fcb04ab18a574af8f9010913a0f745ea223088db6dbee0fa7fce9a4adf9285"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
