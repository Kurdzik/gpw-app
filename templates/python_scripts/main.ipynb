{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"postgresql://j341:ED1F_a359b0@psql01.mikr.us:5432/db_j341\")\n",
    "conn = engine.connect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'ALLEGRO'\n",
    "q_2 = f'''SELECT * FROM gpw_predictors.\"{ticker}\"\n",
    "order by to_date(\"Date\",'dd-mm-yyyy');'''\n",
    "\n",
    "df = pd.read_sql(q_2,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Close_pct'] = df['Close'].pct_change().mul(100)\n",
    "df['Open_pct'] = df['Open'].pct_change().mul(100)\n",
    "df['Max_pct'] = df['Max'].pct_change().mul(100)\n",
    "df['Min_pct'] = df['Min'].pct_change().mul(100)\n",
    "df = df.iloc[1:,:]\n",
    "df = df.drop(columns=['level_0','index','Ticker','Currency','Open','Max','Min','Year'])\n",
    "df['Date'] = pd.to_datetime(df['Date'],dayfirst=True)\n",
    "df = df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from gpw_functions import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from constants import MODELS_FIRST_PART,MODELS_LAST_PART\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "forecast_from = '2022-09-01'\n",
    "predicted_prediod = 10\n",
    "plot_last_mnths = 3\n",
    "\n",
    "def predict_and_plot(preds,train,df,forecst_periods,forecast_from,predicted_prediod,plot_last_mnths,model,ticker,data_type='plot'):\n",
    "\n",
    "    # Get data\n",
    "    \n",
    "    q_2 = f'''SELECT * FROM gpw_predictors.\"{ticker}\"\n",
    "    order by to_date(\"Date\",'dd-mm-yyyy');'''\n",
    "\n",
    "    # preprocess data\n",
    "    df = pd.read_sql(q_2,conn)\n",
    "    df['Close_pct'] = df['Close'].pct_change().mul(100)\n",
    "    df['Open_pct'] = df['Open'].pct_change().mul(100)\n",
    "    df['Max_pct'] = df['Max'].pct_change().mul(100)\n",
    "    df['Min_pct'] = df['Min'].pct_change().mul(100)\n",
    "    df = df.iloc[1:,:]\n",
    "    df = df.drop(columns=['level_0','index','Ticker','Currency','Open','Max','Min','Year'])\n",
    "    df['Date'] = pd.to_datetime(df['Date'],dayfirst=True)\n",
    "    df = df.set_index('Date')\n",
    "\n",
    "\n",
    "\n",
    "    # Dataset parameters\n",
    "    plot_data_since = pd.date_range(end=forecast_from,periods=plot_last_mnths,freq='M')[0].date()\n",
    "\n",
    "    # Train test split\n",
    "    train = df[:forecast_from]['Close']\n",
    "    test = df[forecast_from:]['Close']\n",
    "\n",
    "    # MODEL SELECTION\n",
    "    # ======================================================================================================================\n",
    "    if model == 'Holt Winters - Exponential Smoothing Model':\n",
    "        # MODEL 1 - Holt Winters - Exponential Smoothing\n",
    "        model = ExponentialSmoothing(train,trend='mul',seasonal='mul',seasonal_periods=12).fit()\n",
    "        preds = model.forecast(predicted_prediod)\n",
    "\n",
    "    if model == 'ARIMA':\n",
    "        # MODEL 1 - Holt Winters - Exponential Smoothing\n",
    "        model = ARIMA(df['Close'], order=(1, 0, 0)).fit()\n",
    "\n",
    "\n",
    "        preds = model.forecast(predicted_prediod)\n",
    "\n",
    "\n",
    "    else:\n",
    "        return MODELS_FIRST_PART + 'Model not ready' + MODELS_LAST_PART\n",
    "\n",
    "\n",
    "    # PLOTTING\n",
    "    # ======================================================================================================================\n",
    "    # convert preds from series to \n",
    "    df_preds = preds.to_frame()\n",
    "    df_preds['Date'] = pd.date_range(train.index[-1],periods=forecst_periods);\n",
    "    df_preds = df_preds.rename({0:'Close'},axis=1);\n",
    "    df_preds = df_preds.set_index('Date');\n",
    "\n",
    "    df_train = pd.DataFrame(train);\n",
    "\n",
    "    joint = pd.concat([df_train,df_preds]);\n",
    "\n",
    "    # predictions\n",
    "    pred_data = joint['Close'].iloc[-forecst_periods-1:];\n",
    "\n",
    "    # historical data\n",
    "    hist_data = joint['Close'].iloc[:-forecst_periods];\n",
    "\n",
    "    # true data \n",
    "    pred_idx = pred_data.to_frame().index;\n",
    "    df_test = df['Close'].iloc[len(hist_data)-1 : len(hist_data)+forecst_periods].to_frame().set_index(pred_idx)['Close']\n",
    "\n",
    "    # plot historical data\n",
    "    fig = px.line(hist_data[plot_data_since:], x=hist_data[plot_data_since:].index, y='Close')\n",
    "\n",
    "    # plot predictions\n",
    "    fig.add_scatter(x=df_preds[plot_data_since:].index, y=df_preds[plot_data_since:]['Close'], mode='lines',name='Predictions')\n",
    "\n",
    "    # plot true data\n",
    "    fig.add_scatter(x=df_test.to_frame()[plot_data_since:].index, y=df_test.to_frame()[plot_data_since:]['Close'], mode='lines',name='True data')\n",
    "\n",
    "\n",
    "    if data_type == 'html':\n",
    "        full_html = MODELS_FIRST_PART + fig.to_html()[55:-15] + MODELS_LAST_PART\n",
    "        return full_html\n",
    "\n",
    "    elif data_type == 'plot':\n",
    "        return fig.show()\n",
    "    \n",
    "# plot_predictions(preds=preds,train=train,df=df,forecst_periods=predicted_prediod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_2 = f'''SELECT * FROM gpw_predictors.\"{ticker}\"\n",
    "order by to_date(\"Date\",'dd-mm-yyyy');'''\n",
    "\n",
    "forecast_from = '2022-09-01'\n",
    "forecst_periods = 10\n",
    "plot_last_mnths = 3\n",
    "model = 'SARIMAX'\n",
    "\n",
    "\n",
    "\n",
    "# preprocess data\n",
    "df = pd.read_sql(q_2,conn)\n",
    "df['Close_pct'] = df['Close'].pct_change().mul(100)\n",
    "df['Open_pct'] = df['Open'].pct_change().mul(100)\n",
    "df['Max_pct'] = df['Max'].pct_change().mul(100)\n",
    "df['Min_pct'] = df['Min'].pct_change().mul(100)\n",
    "df = df.iloc[1:,:]\n",
    "df = df.drop(columns=['level_0','index','Ticker','Currency','Open','Max','Min','Year'])\n",
    "df['Date'] = pd.to_datetime(df['Date'],dayfirst=True)\n",
    "df = df.set_index('Date')\n",
    "\n",
    "\n",
    "\n",
    "# Dataset parameters\n",
    "plot_data_since = pd.date_range(end=forecast_from,periods=plot_last_mnths,freq='M')[0].date()\n",
    "\n",
    "# Train test split\n",
    "train = df[:forecast_from]['Close']\n",
    "test = df[forecast_from:]['Close']\n",
    "\n",
    "# MODEL SELECTION\n",
    "# ======================================================================================================================\n",
    "if model == 'Holt Winters - Exponential Smoothing Model':\n",
    "    # MODEL 1 - Holt Winters - Exponential Smoothing\n",
    "    model = ExponentialSmoothing(train,trend='mul',seasonal='mul',seasonal_periods=12).fit()\n",
    "    preds = model.forecast(predicted_prediod)\n",
    "\n",
    "if model == 'ARIMA':\n",
    "    # MODEL 1 - Holt Winters - Exponential Smoothing\n",
    "    model = ARIMA(df['Close'], order=(1, 0, 24)).fit()\n",
    "    preds = model.forecast(predicted_prediod)\n",
    "\n",
    "if model == 'SARIMAX':\n",
    "    # MODEL 1 - Holt Winters - Exponential Smoothing\n",
    "    model = SARIMAX(df['Close'], order=(1, 0, 24)).fit()\n",
    "    preds = model.forecast(predicted_prediod)\n",
    "\n",
    "# else:\n",
    "#     return MODELS_FIRST_PART + 'Model not ready' + MODELS_LAST_PART\n",
    "\n",
    "\n",
    "# PLOTTING\n",
    "# ======================================================================================================================\n",
    "# convert preds from series to \n",
    "df_preds = preds.to_frame()\n",
    "df_preds['Date'] = pd.date_range(train.index[-1],periods=forecst_periods);\n",
    "df_preds = df_preds.rename({0:'Close'},axis=1);\n",
    "df_preds = df_preds.set_index('Date');\n",
    "\n",
    "df_train = pd.DataFrame(train);\n",
    "\n",
    "joint = pd.concat([df_train,df_preds]);\n",
    "\n",
    "# predictions\n",
    "pred_data = joint['Close'].iloc[-forecst_periods-1:];\n",
    "\n",
    "# historical data\n",
    "hist_data = joint['Close'].iloc[:-forecst_periods];\n",
    "\n",
    "# true data \n",
    "pred_idx = pred_data.to_frame().index;\n",
    "df_test = df['Close'].iloc[len(hist_data)-1 : len(hist_data)+forecst_periods].to_frame().set_index(pred_idx)['Close']\n",
    "\n",
    "# plot historical data\n",
    "fig = px.line(hist_data[plot_data_since:], x=hist_data[plot_data_since:].index, y='Close')\n",
    "\n",
    "# plot predictions\n",
    "fig.add_scatter(x=df_preds[plot_data_since:].index, y=df_preds[plot_data_since:].rename({'predicted_mean':'Close'},axis=1)['Close'], mode='lines',name='Predictions')\n",
    "\n",
    "# plot true data\n",
    "fig.add_scatter(x=df_test.to_frame()[plot_data_since:].index, y=df_test.to_frame()[plot_data_since:]['Close'], mode='lines',name='True data')\n",
    "\n",
    "# fig.show()\n",
    "# if data_type == 'html':\n",
    "#     full_html = MODELS_FIRST_PART + fig.to_html()[55:-15] + MODELS_LAST_PART\n",
    "#     return full_html\n",
    "\n",
    "# elif data_type == 'plot':\n",
    "#     return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_frame()[plot_data_since:]['Close']\n",
    "df_test.to_frame()[plot_data_since:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_1 = '''SELECT distinct \"Ticker\"\n",
    "FROM gpw.notowania;'''\n",
    "df_all_tickers = pd.read_sql(q_1,conn)\n",
    "\n",
    "\n",
    "list_of_existing_tickers = []\n",
    "\n",
    "for ticker in list(df_all_tickers['Ticker']):\n",
    "\n",
    "    q_2 = f'''SELECT * FROM gpw_predictors.\"{ticker}\"\n",
    "    order by to_date(\"Date\",'dd-mm-yyyy');'''\n",
    "\n",
    "    try:\n",
    "        df_if_exist = pd.read_sql(q_2,conn)\n",
    "        if len(df_if_exist)>0:\n",
    "            list_of_existing_tickers.append(ticker)\n",
    "            print(ticker, 'added')\n",
    "            \n",
    "    except Exception:\n",
    "        print(ticker, 'not found')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(list_of_existing_tickers).sort_values().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpw_functions import get_stock_prices\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "engine = create_engine(\"postgresql://j341:ED1F_a359b0@psql01.mikr.us:5432/db_j341\")\n",
    "# engine = create_engine(conn_string)\n",
    "conn = engine.connect()\n",
    "\n",
    "\n",
    "def day():\n",
    "    if date.today().day<10:\n",
    "        return '0' + str(date.today().day)\n",
    "    else:\n",
    "        return str(date.today().day)\n",
    "\n",
    "def month():\n",
    "    if date.today().month<10:\n",
    "        return '0' + str(date.today().month)\n",
    "    else:\n",
    "        return str(date.today().month)\n",
    "    \n",
    "def year():\n",
    "    if date.today().year<10:\n",
    "        return '0' + str(date.today().year)\n",
    "    else:\n",
    "        return str(date.today().year)\n",
    "\n",
    "# Get date in a correct format\n",
    "stocs_date = f'{day()}-{month()}-{year()}'\n",
    "\n",
    "# Get stock prices for that date\n",
    "data = get_stock_prices('01-09-2022',stocs_date)\n",
    "if len(data)>0:\n",
    "    # Get all registered connection stirings\n",
    "\n",
    "    creds = pd.read_sql('select * from connected_dbs.connections', con=conn)\n",
    "\n",
    "    # Iterate through conn strings and upload the data\n",
    "    for conn_string in creds.iterrows():\n",
    "        try:\n",
    "            data.to_sql(conn_string[1][1],con = conn_string[1][0], schema = conn_string[1][2],if_exists = 'append')\n",
    "        except Exception:\n",
    "            continue\n",
    "else: print('No records collected today')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "# engine = sqlalchemy.create_engine(conn_string)\n",
    "# conn = engine.connect()\n",
    "\n",
    "q = f\"\"\"select distinct * from gpw.notowania\"\"\"\n",
    "df = pd.read_sql(q,con=conn)\n",
    "\n",
    "dates_list = []\n",
    "for date in pd.to_datetime(df['Date'],format=\"%d-%m-%Y\").sort_values().unique().astype(str):\n",
    "    dates_list.append(date[:10])\n",
    "   \n",
    "# Updae dates dropdowns\n",
    "with open('../static/dropdown/dates_to.csv','w') as file:\n",
    "    for line in dates_list:\n",
    "        file.write(line + ',')\n",
    "        file.write('\\n')\n",
    "\n",
    "shutil.copy('../static/dropdown/dates_to.csv','../static/dropdown/dates_from.csv')\n",
    "\n",
    "# Update prediction tickers dropdown\n",
    "q_1 = '''SELECT distinct \"Ticker\" FROM gpw.notowania;'''\n",
    "df_all_tickers = pd.read_sql(q_1,conn)\n",
    "\n",
    "list_of_existing_tickers = []\n",
    "\n",
    "for ticker in list(df_all_tickers['Ticker']):\n",
    "\n",
    "    q_2 = f'''SELECT * FROM gpw_predictors.\"{ticker}\"\n",
    "    order by to_date(\"Date\",'dd-mm-yyyy');'''\n",
    "\n",
    "    try:\n",
    "        df_if_exist = pd.read_sql(q_2,conn)\n",
    "        if len(df_if_exist)>0:\n",
    "            list_of_existing_tickers.append(ticker)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "with open('../static/dropdown/tickers_preds.csv','w') as file:\n",
    "    for line in pd.Series(list_of_existing_tickers).sort_values().to_list():\n",
    "        file.write(line + ',')\n",
    "        file.write('\\n')\n",
    "\n",
    "# Update tickers dropdown\n",
    "with open('../static/dropdown/tickers.csv','w') as file:\n",
    "    for line in ['ALL'] + df['Ticker'].unique().tolist():\n",
    "        file.write(line + ',')\n",
    "        file.write('\\n')\n",
    "\n",
    "# Clear downloads\n",
    "path = '../static/downloads/'\n",
    "if len(os.listdir(path))>0:\n",
    "    for file in os.listdir(path):\n",
    "        if '.gitkeep' != file:\n",
    "            os.remove(path + file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "df = pd.read_csv('../static/downloads/stocks_2010-01-04-2010-01-12.csv')\n",
    "\n",
    "fig = px.line(df, x=\"Date\", y=\"Close\", title='06MAGNA')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://test_user:Kolesgit99!@192.168.88.199:3307/GPW?charset=utf8mb4\")\n",
    "conn_str_maria = engine.connect()\n",
    "\n",
    "engine = create_engine(\"postgresql://j341:ED1F_a359b0@psql01.mikr.us:5432/db_j341\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "# import pandas as pd\n",
    "# mapa = pd.read_sql('select * from mapowanie',con=conn_str_maria)\n",
    "\n",
    "# mapa.to_sql('mapowanie',con=conn,schema='gpw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpw_functions import map_financial_data,get_stock_prices\n",
    "\n",
    "df = get_stock_prices(date_from='16-09-2022',date_to='16-09-2022')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_financial_data(df,conn)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv('missing_companies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpw_functions import get_stock_prices\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"postgresql://j341:ED1F_a359b0@psql01.mikr.us:5432/db_j341\")\n",
    "conn = engine.connect()\n",
    "\n",
    "starts = ['01-01-2010','01-01-2011','01-01-2012','01-01-2013','01-01-2014','01-01-2015','01-01-2016','01-01-2017','01-01-2018','01-01-2019','01-01-2020','01-01-2021','01-01-2022']\n",
    "stops = ['31-12-2010','31-12-2011','31-12-2012','31-12-2013','31-12-2014','31-12-2015','31-12-2016','31-12-2017','31-12-2018','31-12-2019','31-12-2020','31-12-2021','09-09-2022']\n",
    "\n",
    "for start,stop in zip(starts,stops):\n",
    "\n",
    "    df = get_stock_prices(start,stop)\n",
    "    df.to_sql('notowania',schema='gpw',con=conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MM DD RRRR\n",
    "date_from = '02-01-2015'\n",
    "day_from = date_from[:2]\n",
    "month_from = date_from[3:5]\n",
    "year_from = date_from[-4:]\n",
    "\n",
    "date_to = '05-01-2015'\n",
    "day_to = date_to[:2]\n",
    "month_to = date_to[3:5]\n",
    "year_to = date_to[-4:]\n",
    "\n",
    "\n",
    "q = f\"\"\"select * from gpw.notowania where Date_new > '{year_from}-{month_from}-{day_from}' and Date_new <= '{year_to}-{month_to}-{day_to}' \"\"\"\n",
    "\n",
    "df = pd.read_sql(q,con=conn).drop(columns=['level_0','index'])\n",
    "df.loc[df['Ticker'].str.contains('06')]\n",
    "\n",
    "## POTRZEBA RRRR MM DD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Date'] = df.Date.apply(lambda x: str(x))\n",
    "df['Date_new'] = df.Date.str[-4:]+'-'+df.Date.str[3:5]+'-'+df.Date.str[:2]\n",
    "df.to_sql('notowania',con=conn, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_db(date_from,date_to,ticker):\n",
    "    \n",
    "    engine = create_engine(\"mysql+pymysql://test_user:Kolesgit99!@192.168.88.199:3307/GPW?charset=utf8mb4\")\n",
    "    conn = engine.connect()\n",
    "\n",
    "    q = f\"\"\"select * from notowania where Date_new > '{year_from}-{month_from}-{day_from}' and Date_new <= '{year_to}-{month_to}-{day_to}' \"\"\"\n",
    "\n",
    "    df = pd.read_sql(q,con=conn).drop(columns=['level_0','index'])\n",
    "\n",
    "\n",
    "    if ticker=='ALL':\n",
    "        return df\n",
    "        \n",
    "    else:\n",
    "        return df.loc[df['Ticker'].str.contains(ticker)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_conn(db_type,db_user,db_pass,db_ip,db_port,database):\n",
    "\n",
    "    if db_type=='PostgreSQL':\n",
    "        engine = create_engine(f\"\"\"postgresql://{db_user}:{db_pass}@{db_ip}:{db_port}/{database}\"\"\")      \n",
    "\n",
    "    elif db_type=='MySQL':\n",
    "        engine = create_engine(f\"\"\"mysql://{db_user}:{db_pass}@{db_ip}:{db_port}/{database}\"\"\")\n",
    "\n",
    "    elif db_type=='Oracle':\n",
    "        engine = create_engine(f\"\"\"oracle://{db_user}:{db_pass}@{db_ip}:{db_port}/{database}\"\"\")\n",
    "\n",
    "    elif db_type=='SQL Server':\n",
    "        engine = create_engine(f\"\"\"mssql+pymssql://{db_user}:{db_pass}@{db_ip}:{db_port}/{database}\"\"\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        engine.connect()\n",
    "        msg = 'Connected!'        \n",
    "        return engine, msg\n",
    "\n",
    "    except Exception:\n",
    "        msg = 'Check your db credentials'\n",
    "        return engine, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('../static/db_credentials/creds.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "conn_str = ['postgresql://test_user:Kolesgit99!@192.168.88.199:3306/otomoto','active']\n",
    "pd.DataFrame(conn_str).T.rename({0:'connection_string',1:'status'},axis=1).to_sql('connections',if_exists='append',con=conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"postgresql://j341:ED1F_a359b0@psql01.mikr.us:5432/db_j341\")\n",
    "conn = engine.connect()\n",
    "\n",
    "from gpw_functions import get_stock_prices,map_financial_data\n",
    "\n",
    "\n",
    "# q = 'select * from connections'\n",
    "# pd.read_sql(q,con=conn)\n",
    "df = get_stock_prices(date_from='16-09-2022',date_to='16-09-2022')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "\n",
    "for col in df.columns:\n",
    "    try: \n",
    "        df[col] = df[col].apply(unidecode.unidecode).apply(lambda x: x.replace(' ','')).apply(float)\n",
    "        df[col] = df[col]\n",
    "    except: continue \n",
    "\n",
    "# df['Close'] = df['Close'].apply(lambda x: x.replace(' ',''))\n",
    "# df['Close'] = df['Close'].apply(float)\n",
    "\n",
    "# for line in df['Close']:\n",
    "#     try: float(line)\n",
    "\n",
    "#     except: val = line\n",
    "\n",
    "df.info()\n",
    "x1, x2, x3, x4 = map_financial_data(df,conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import os\n",
    "from gpw_functions import map_financial_data\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"postgresql://j341:ED1F_a359b0@psql01.mikr.us:5432/db_j341\")\n",
    "conn = engine.connect()\n",
    "\n",
    "\n",
    "# # get all data\n",
    "# q = f\"\"\"select distinct * from gpw.notowania \"\"\"\n",
    "# df_all = pd.read_sql(q,con=conn)\n",
    "\n",
    "# get all tickers\n",
    "# q = f\"\"\"SELECT distinct \"Ticker\" FROM gpw.notowania order by \"Ticker\";\"\"\"\n",
    "# tickers = pd.read_sql(q,con=conn)\n",
    "\n",
    "# import itertools\n",
    "\n",
    "# print(len([x[0] for x in tickers.values]))\n",
    "# print([x[0] for x in tickers.values].index('SWISSMED'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# url = 'https://www.biznesradar.pl/raporty-finansowe-rachunek-zyskow-i-strat/06MAGNA'\n",
    "# requests.get(url).status_code==200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import unidecode\n",
    "import plotly.express as px\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"postgresql://j341:ED1F_a359b0@psql01.mikr.us:5432/db_j341\")\n",
    "conn = engine.connect()\n",
    "\n",
    "\n",
    "def convert_to_floats(df):\n",
    "    for col in df.columns:\n",
    "        try: \n",
    "            df[col] = df[col].apply(unidecode.unidecode).apply(lambda x: x.replace(' ','')).apply(float)\n",
    "        except Exception: continue \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#================================================================================================================\n",
    "q_rzis = \"\"\"SELECT *\n",
    "FROM \"gpw_RZiS\".\"06MAGNA\";\n",
    "\"\"\"\n",
    "try:\n",
    "    df_rzis = pd.read_sql(q_rzis,con=conn).drop(columns='index').rename({'O4K ':'2022','Inde':'index'},axis=1).set_index('index').T.reset_index()\n",
    "    df_rzis = convert_to_floats(df_rzis)\n",
    "except Exception:\n",
    "    df_rzis = None\n",
    "#================================================================================================================\n",
    "q_cf = \"\"\"SELECT *\n",
    "FROM \"gpw_CF\".\"06MAGNA\";\n",
    "\"\"\"\n",
    "try:\n",
    "    df_cf = pd.read_sql(q_cf,con=conn).drop(columns='index').rename({'O4K ':'2022','Inde':'index'},axis=1).set_index('index').T.reset_index()\n",
    "    df_cf = convert_to_floats(df_cf)\n",
    "except Exception:\n",
    "    df_cf = None\n",
    "#================================================================================================================\n",
    "\n",
    "q_bs = \"\"\"SELECT *\n",
    "FROM \"gpw_BS\".\"06MAGNA\";\n",
    "\"\"\"\n",
    "try:\n",
    "    df_bs = pd.read_sql(q_bs,con=conn).drop(columns='index').rename({'O4K ':'2022','Inde':'index'},axis=1).set_index('index').T.reset_index()\n",
    "    df_bs = convert_to_floats(df_bs)\n",
    "    df_bs['Total liabilities'] = df_bs['Aktywa razem'] - df_bs['Kapitał własny akcjonariuszy jednostki dominującej'] - df_bs['Kapitał (fundusz) podstawowy'] - df_bs['Udziały (akcje) własne'] - df_bs['Kapitał (fundusz) zapasowy'] - df_bs['Udziały niekontrolujące']\n",
    "except Exception:\n",
    "    df_bs = None\n",
    "\n",
    "#================================================================================================================\n",
    "q_pred = \"\"\"SELECT *\n",
    "FROM \"gpw_predictors\".\"06MAGNA\" order by TO_DATE(\"Date\",'DD-MM-YYYY');\n",
    "\"\"\"\n",
    "try:\n",
    "    df_pred = pd.read_sql(q_pred,con=conn).drop(columns=['index','level_0'])\n",
    "    df_pred = convert_to_floats(df_pred)\n",
    "except Exception:\n",
    "    df_pred = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "#======== Profitability ================================================================================================================================================================================================\n",
    "# Graph 1 - (sales revenue) Przychody ze sprzedaży vs (COGS) Techniczny koszt wytworzenia produkcji sprzedanej + Koszty sprzedaży + Koszty ogólnego zarządu\n",
    "try: fig1 = px.bar(data_frame=df_rzis.rename({'Przychody ze sprzedaży':'Sales Revenue','Zysk netto':'Net Profit'},axis=1)\n",
    "                    ,y='Sales Revenue',x='index').data[0]\n",
    "except Exception: fig1 = px.bar(x=[0],y=[0]).data[0]\n",
    "\n",
    "# Graph 2 - (net profit) Zysk netto\n",
    "try: fig2 = px.bar(data_frame=df_rzis.rename({'Przychody ze sprzedaży':'Sales Revenue','Zysk netto':'Net Profit'},axis=1)\n",
    "                    ,y='Net Profit',x='index',color='Net Profit').data[0]\n",
    "except Exception: fig2 = px.bar(x=[0],y=[0]).data[0]\n",
    "\n",
    "#======== Liquidity ====================================================================================================================================================================================================\n",
    "# Graph 3 - (cash flow from operations) Przepływy pieniężne z działalności operacyjnej\n",
    "try: fig3 = px.bar(data_frame=df_cf.rename({'Przepływy pieniężne z działalności operacyjnej':'CF from operations','Przepływy pieniężne razem':'Total CF'},axis=1)\n",
    "                    ,y='CF from operations',x='index',color='CF from operations').data[0]\n",
    "except Exception: fig3 = px.bar(x=[0],y=[0]).data[0]\n",
    "\n",
    "# Graph 4 - (total cash flow) Przepływy pieniężne razem\n",
    "try: fig4 = px.bar(data_frame=df_cf.rename({'Przepływy pieniężne z działalności operacyjnej':'CF from operations','Przepływy pieniężne razem':'Total CF'},axis=1)\n",
    "                    ,y='Total CF',x='index',color='Total CF').data[0]\n",
    "except Exception: fig4 = px.bar(x=[0],y=[0]).data[0]\n",
    "\n",
    "#======== Balance Sheet ================================================================================================================================================================================================\n",
    "# Graph 5 - (total assets) Aktywa razem\n",
    "try: fig5 = px.bar(data_frame=df_bs.rename({'Aktywa razem':'Total assets'},axis=1),\n",
    "                    y='Total assets',x='index').data[0]\n",
    "except Exception: fig5 = px.bar(x=[0],y=[0]).data[0]\n",
    "\n",
    "# Graph 6 - (total liabilities) Aktywa razem - Kapitał własny akcjonariuszy jednostki dominującej - Kapitał (fundusz) podstawowy - Udziały (akcje) własne - Kapitał (fundusz) zapasowy - Udziały niekontrolujące\n",
    "try: fig6 = px.bar(data_frame=df_bs,y='Total liabilities',x='index').data[0]\n",
    "except Exception: fig6 = px.bar(x=[0],y=[0]).data[0]\n",
    "\n",
    "#======== Indicators ===================================================================================================================================================================================================\n",
    "# Graph 7 - (P/E) C/Z\n",
    "try: fig7 = px.line(data_frame=df_pred.rename({'C/Z':'P/E'},axis=1)\n",
    "                    ,y='P/E',x='Date').data[0]\n",
    "except Exception: fig7 = px.bar(x=[0],y=[0]).data[0]\n",
    "\n",
    "# Graph 8 - (P/BW) C/WK\n",
    "try: fig8 = px.line(data_frame=df_pred.rename({'C/WK':'P/BV'},axis=1)\n",
    "                    ,y='P/BV',x='Date').data[0]\n",
    "except Exception: fig8 = px.bar(x=[0],y=[0]).data[0]\n",
    "\n",
    "# Graph 9 - (EV/EBITDA) EV/EBITDA\n",
    "try: fig9 = px.line(data_frame=df_pred,y='EV / EBITDA',x='Date').data[0]\n",
    "except Exception: fig9 = px.bar(x=[0],y=[0]).data[0]\n",
    "\n",
    "#======== Figures =====================================================================================================================================================================================================\n",
    "fig_list = [fig1,fig2,fig3,fig4,fig5,fig6,fig7,fig8,fig9]\n",
    "\n",
    "fig = make_subplots(rows=9, cols=1,subplot_titles=(\"Sales Revenue\", \"Net Profit/Loss\", \"Cash flow from operations\", \"Total cash flow\",\"Total assets\",\"Total liabilities\",\"Price to Earnings indicator\",\"Price to Book Value indicator \",\"Enterpise Value to EBITDA indicator\"))\n",
    "for i,fig_ in enumerate(fig_list):\n",
    "    fig.add_trace(fig_, row=i + 1, col=1)\n",
    "\n",
    "fig.update_layout(height=3000, width=1500, title_text=\"Financial data\",coloraxis=dict(colorscale='temps_r'))\n",
    "fig.to_html()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dashboards_refresh import get_and_plot_data\n",
    "\n",
    "stuff = get_and_plot_data('CDPROJEKT',data_type = 'html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dashboards.html','w') as file:\n",
    "    file.write(stuff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('app_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14fcb04ab18a574af8f9010913a0f745ea223088db6dbee0fa7fce9a4adf9285"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
